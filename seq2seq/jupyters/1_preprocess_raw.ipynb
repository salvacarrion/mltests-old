{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = f\"../.data/miguel\"\n",
    "SRC_LANG = \"en\"\n",
    "TRG_LANG = \"es\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "This dataset is made up of two files (src, trg) for each split (train, dev and test). All files are in plain text with UTF-8 encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename_src, filename_trg):\n",
    "    file_src = open(filename_src, encoding='utf-8').read().split('\\n')\n",
    "    file_trg = open(filename_trg, encoding='utf-8').read().split('\\n')\n",
    "    assert len(file_src) == len(file_trg)\n",
    "    return file_src, file_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "(train_src, train_trg) = load_dataset(filename_src=f\"{DATASET_PATH}/raw/europarl.en\", filename_trg=f\"{DATASET_PATH}/raw/europarl.es\")\n",
    "(dev_src, dev_trg) = load_dataset(filename_src=f\"{DATASET_PATH}/raw/dev.en\", filename_trg=f\"{DATASET_PATH}/raw/dev.es\")\n",
    "(test_src, test_trg) = load_dataset(filename_src=f\"{DATASET_PATH}/raw/test.en\", filename_trg=f\"{DATASET_PATH}/raw/test.es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train => Total sentences: SRC=1960642 | TRG=1960642\n",
      "Dev => Total sentences: SRC=3004 | TRG=3004\n",
      "Test => Total sentences: SRC=3001 | TRG=3001\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train => Total sentences: SRC={len(train_src)} | TRG={len(train_trg)}\")\n",
    "print(f\"Dev => Total sentences: SRC={len(dev_src)} | TRG={len(dev_trg)}\")\n",
    "print(f\"Test => Total sentences: SRC={len(test_src)} | TRG={len(test_trg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative exploration\n",
    "\n",
    "By simply opening the text files and exploring them, I have noticed the following things:\n",
    "\n",
    "**Train:**\n",
    "- Two files (en, es)\n",
    "- `<0 `\n",
    "- Chars like: `NBSP`\n",
    "- Short sentences, around 50-100 words\n",
    "- Sentences starting with `(`\n",
    "- UTF-8\n",
    "- No tokenization done (like replacing numbers with `NUM`, dates with `DATE` or things like that)\n",
    "- Words/Sentences hard to translate: `(H-0521/00)`, `78/319/CEE`\n",
    "- Last line empty\n",
    "- Some sentences end with period, others don't\n",
    "\n",
    "**Dev:**\n",
    "- Two files (en, es)\n",
    "- Chars like: `NBSP`, `ZWSP`\n",
    "- Short sentences, around 50-100 words\n",
    "- Sentences starting with `\"`\n",
    "- UTF-8\n",
    "- No tokenization done (like replacing numbers with `NUM`, dates with `DATE` or things like that)\n",
    "- Words/Sentences hard to translate: `Wolfgang Schäuble`, `Hašek`\n",
    "- Last line empty\n",
    "- Some sentences end with period, others don't\n",
    "\n",
    "\n",
    "**Test:**\n",
    "- Two files (en, es)\n",
    "- `<seg id=` tags\n",
    "- Chars like: `NBSP`, `ZWSP`\n",
    "- Short sentences, around 50-100 words\n",
    "- Sentences starting with `\"`\n",
    "- UTF-8\n",
    "- No tokenization done (like replacing numbers with `NUM`, dates with `DATE` or things like that)\n",
    "- Words/Sentences hard to translate: `Nikolaev`, `www.kpks.cz`, `(0-0)`\n",
    "- Last line empty\n",
    "- Some sentences end with period, others don't\n",
    "- Multiple formats for datates: `20.12.2012`\n",
    "\n",
    "\n",
    "**File sizes:**\n",
    "\n",
    "```bash\n",
    "-rw-r--r-- 1 salvacarrion salvacarrion 373K ene 23  2013 dev.en\n",
    "-rw-r--r-- 1 salvacarrion salvacarrion 417K ene 23  2013 dev.es\n",
    "-rw-rw-r-- 1 salvacarrion salvacarrion 281M mar 31  2020 europarl.en\n",
    "-rw-rw-r-- 1 salvacarrion salvacarrion 310M mar 31  2020 europarl.es\n",
    "-rw-r--r-- 1 salvacarrion salvacarrion 329K mar 31  2020 test.en\n",
    "-rw-r--r-- 1 salvacarrion salvacarrion 374K mar 31  2020 test.es\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head and tails\n",
    "\n",
    "Now, I want to see the first and last *n* pairs of sentences for each partition to check whether everything has been readed properly and matches the head and tail of the raw-text files.\n",
    "\n",
    "Below we see that there is nothing strange here, except that we need to peform some cleaning (removing the empty line, xml tags, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def view_raw(src_raw, trg_raw, indices):\n",
    "    for i, idx in enumerate(indices):\n",
    "        (src, trg) = src_raw[idx], trg_raw[idx]\n",
    "        print(f\"#{i+1}: \" + \"-\"*20)\n",
    "        print(f\"src => {src}\")\n",
    "        print(f\"trg => {trg}\")\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head: ####################\n",
      "(Firsts) Train dataset: ********************\n",
      "#1: --------------------\n",
      "src => Resumption of the session\n",
      "trg => Reanudación del período de sesiones\n",
      "#2: --------------------\n",
      "src => I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "trg => Declaro reanudado el período de sesiones del Parlamento Europeo, interrumpido el viernes 17 de diciembre pasado, y reitero a Sus Señorías mi deseo de que hayan tenido unas buenas vacaciones.\n",
      "#3: --------------------\n",
      "src => Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "trg => Como todos han podido comprobar, el gran \"efecto del año 2000\" no se ha producido. En cambio, los ciudadanos de varios de nuestros países han sido víctimas de catástrofes naturales verdaderamente terribles.\n",
      "\n",
      "(Firsts) Dev dataset: ********************\n",
      "#1: --------------------\n",
      "src => Parliament Does Not Support Amendment Freeing Tymoshenko\n",
      "trg => El parlamento no apoyó una enmienda para liberar a Tymoshenko\n",
      "#2: --------------------\n",
      "src => Today, the Ukraine parliament dismissed, within the Code of Criminal Procedure amendment, the motion to revoke an article based on which the opposition leader, Yulia Tymoshenko, was sentenced.\n",
      "trg => El Parlamento de Ucrania ha rechazado hoy la propuesta de derogar la enmienda de la sección del Código Penal en la que se condena a la líder de la oposición Yulia Tymoshenko.\n",
      "#3: --------------------\n",
      "src => The amendment that would lead to freeing the imprisoned former Prime Minister was revoked during second reading of the proposal for mitigation of sentences for economic offences.\n",
      "trg => La modificación abriría las puertas a la excarcelación de la exprimer ministra, pero los parlamentarios rechazaron la propuesta de reducir las penas por delitos económicos en la segunda lectura.\n",
      "\n",
      "(Firsts) Test dataset: ********************\n",
      "#1: --------------------\n",
      "src => A Republican strategy to counter the re-election of Obama \n",
      "trg => Una estrategia republicana para obstaculizar la reelección de Obama\n",
      "#2: --------------------\n",
      "src => Republican leaders justified their policy by the need to combat electoral fraud.\n",
      "trg => Los dirigentes republicanos justificaron su política por la necesidad de luchar contra el fraude electoral.\n",
      "#3: --------------------\n",
      "src => However, the Brennan Centre considers this a myth, stating that electoral fraud is rarer in the United States than the number of people killed by lightning.\n",
      "trg => Ahora bien, el Centro Brennan considera esto último un mito y afirma que el fraude electoral es menos frecuente en los Estados Unidos que el número de personas que mueren a causa de la caída de un rayo.\n",
      "\n",
      "Tail: ####################\n",
      "(Lasts) Train dataset: ********************\n",
      "#1: --------------------\n",
      "src => \n",
      "trg => \n",
      "#2: --------------------\n",
      "src => (The sitting was closed at 10.50 a.m.)\n",
      "trg => (Se levanta la sesión a las 10.50 horas)\n",
      "#3: --------------------\n",
      "src => I declare the session of the European Parliament adjourned.\n",
      "trg => Declaro interrumpido el período de sesiones del Parlamento Europeo.\n",
      "\n",
      "(Lasts) Dev dataset: ********************\n",
      "#1: --------------------\n",
      "src => \n",
      "trg => \n",
      "#2: --------------------\n",
      "src => A good idea, provided that it will, prove realistic this time.\n",
      "trg => Una buena idea, siempre que, esta vez, sea realista.\n",
      "#3: --------------------\n",
      "src => As already in Zenica, the Portuguese would plan to exert maximal pressure on the Bosnians from the start, to \"give them no time to think.\"\n",
      "trg => Al igual que en Zenica, los portugueses irán con la intención de ejercer, desde el principio, una presión máxima sobre los bosnios para \"no dejarles tiempo a pensar\".\n",
      "\n",
      "(Lasts) Test dataset: ********************\n",
      "#1: --------------------\n",
      "src => \n",
      "trg => \n",
      "#2: --------------------\n",
      "src => \"Maybe I'll call some friends so we can have a laugh together\" said Samira Ford, 20-year-old communications student.\n",
      "trg => \"Tal vez llame a algunos amigos para que nos riamos juntos\", comentó Samira Ford, estudiante de comunicaciones de 20 años.\n",
      "#3: --------------------\n",
      "src => <seg id=\"40\">Some said they plan to go to \"end of the world\" parties.\n",
      "trg => <seg id=\"40\">Varios dijeron que piensan ir a fiestas \"del fin del mundo\".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "print(\"Head: \" + \"#\"*20)\n",
    "print(\"(Firsts) Train dataset: \" + \"*\"*20)\n",
    "view_raw(train_src, train_trg, indices=range(0, n))\n",
    "\n",
    "print(\"(Firsts) Dev dataset: \" + \"*\"*20)\n",
    "view_raw(dev_src, dev_trg, indices=range(0, n))\n",
    "\n",
    "print(\"(Firsts) Test dataset: \" + \"*\"*20)\n",
    "view_raw(test_src, test_trg, indices=range(0, n))\n",
    "\n",
    "print(\"Tail: \" + \"#\"*20)\n",
    "print(\"(Lasts) Train dataset: \" + \"*\"*20)\n",
    "view_raw(train_src, train_trg, indices=range(-1,-n-1,-1))\n",
    "\n",
    "print(\"(Lasts) Dev dataset: \" + \"*\"*20)\n",
    "view_raw(dev_src, dev_trg, indices=range(-1,-n-1,-1))\n",
    "\n",
    "print(\"(Lasts) Test dataset: \" + \"*\"*20)\n",
    "view_raw(test_src, test_trg, indices=range(-1,-n-1,-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dataset\n",
    "\n",
    "From the previous exploration we've seen that we need to perform a bit of preprocessing. Here, I'll apply the same cleaning to each partition, regaless the language, since it is a pretty general cleaning. Cleaning steps:\n",
    "\n",
    "- Remove last empty row from: Train, Dev and Test\n",
    "- Remove XML tags\n",
    "- Remove multiple whitespaces\n",
    "- Strip lines\n",
    "- Remove pair, if any of the lines is empty\n",
    "\n",
    "I could also set everything to lowercase, but I prefer to leave that for the tokenizer, and have the preprocessed files as \"raw\" as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define regex patterns\n",
    "p_xml = re.compile(\"^<seg id=\\\"\\d+\\\">\")\n",
    "p_whitespace = re.compile(\" +\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove html\n",
    "    text = p_xml.sub('', text)\n",
    "\n",
    "    # Remove repeated whitespaces \"   \" => \" \"\n",
    "    text = p_whitespace.sub(' ', text)\n",
    "\n",
    "    # Normalization Form Compatibility Composition\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "     # Strip whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(data_src, data_trg):\n",
    "    data_src_new, data_trg_new = [], []\n",
    "\n",
    "\n",
    "    total = len(data_src)\n",
    "    for i in tqdm(range(total), total=total):\n",
    "        src, trg = data_src[i], data_trg[i]\n",
    "\n",
    "        # Preprocess\n",
    "        src = preprocess_text(src)\n",
    "        trg = preprocess_text(trg)\n",
    "\n",
    "        # Remove empty line\n",
    "        if len(src) > 0 and len(trg) > 0:\n",
    "            data_src_new.append(src)\n",
    "            data_trg_new.append(trg)\n",
    "    return data_src_new, data_trg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960642/1960642 [00:31<00:00, 63060.33it/s]\n",
      "100%|██████████| 3004/3004 [00:00<00:00, 74557.90it/s]\n",
      "100%|██████████| 3001/3001 [00:00<00:00, 80385.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "train_src, train_trg = preprocess_dataset(train_src, train_trg)\n",
    "dev_src, dev_trg = preprocess_dataset(dev_src, dev_trg)\n",
    "test_src, test_trg = preprocess_dataset(test_src, test_trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check the number of pairs again**\n",
    "\n",
    "After the cleanning process, we see that only one pair from each file has been remove (the empty line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train => Total sentences: SRC=1960641 | TRG=1960641\n",
      "Dev => Total sentences: SRC=3003 | TRG=3003\n",
      "Test => Total sentences: SRC=3000 | TRG=3000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train => Total sentences: SRC={len(train_src)} | TRG={len(train_trg)}\")\n",
    "print(f\"Dev => Total sentences: SRC={len(dev_src)} | TRG={len(dev_trg)}\")\n",
    "print(f\"Test => Total sentences: SRC={len(test_src)} | TRG={len(test_trg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Pandas to CSV\n",
    "\n",
    "Once we have the raw file \"cleaned\", we can convert them to Pandas and the to CSV.\n",
    "\n",
    "Pandas is a astonishingly good library for working with tabular data. However, here I simply use it to save the CSV file. Finally, the reason behind using CSV is that it is an easy-to-read format, widely supported by many libraries in the Python data science stack. Additionally, it can be easily compressed with high storage savings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_raw = {SRC_LANG: train_src, TRG_LANG: train_trg}\n",
    "train_df = pd.DataFrame(train_raw, columns=[SRC_LANG, TRG_LANG])\n",
    "\n",
    "dev_raw = {SRC_LANG: dev_src, TRG_LANG: dev_trg}\n",
    "dev_df = pd.DataFrame(dev_raw, columns=[SRC_LANG, TRG_LANG])\n",
    "\n",
    "test_raw = {SRC_LANG: test_src, TRG_LANG: test_trg}\n",
    "test_df = pd.DataFrame(test_raw, columns=[SRC_LANG, TRG_LANG])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview pandas**\n",
    "\n",
    "Now we take a look at the Pandas object before saving it to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "                                                        en  \\\n",
      "0                                Resumption of the session   \n",
      "1        I declare resumed the session of the European ...   \n",
      "2        Although, as you will have seen, the dreaded '...   \n",
      "3        You have requested a debate on this subject in...   \n",
      "4        In the meantime, I should like to observe a mi...   \n",
      "...                                                    ...   \n",
      "1960636  I would also like, although they are absent, t...   \n",
      "1960637  I am not going to re-open the 'Millennium or n...   \n",
      "1960638                         Adjournment of the session   \n",
      "1960639  I declare the session of the European Parliame...   \n",
      "1960640             (The sitting was closed at 10.50 a.m.)   \n",
      "\n",
      "                                                        es  \n",
      "0                      Reanudación del período de sesiones  \n",
      "1        Declaro reanudado el período de sesiones del P...  \n",
      "2        Como todos han podido comprobar, el gran \"efec...  \n",
      "3        Sus Señorías han solicitado un debate sobre el...  \n",
      "4        A la espera de que se produzca, de acuerdo con...  \n",
      "...                                                    ...  \n",
      "1960636  Incluso me permitiría, aunque estén ausentes, ...  \n",
      "1960637  No voy a abrir otra vez el debate sobre \"milen...  \n",
      "1960638               Interrupción del periodo de sesiones  \n",
      "1960639  Declaro interrumpido el período de sesiones de...  \n",
      "1960640           (Se levanta la sesión a las 10.50 horas)  \n",
      "\n",
      "[1960641 rows x 2 columns]\n",
      "Dev:\n",
      "                                                     en  \\\n",
      "0     Parliament Does Not Support Amendment Freeing ...   \n",
      "1     Today, the Ukraine parliament dismissed, withi...   \n",
      "2     The amendment that would lead to freeing the i...   \n",
      "3     In October, Tymoshenko was sentenced to seven ...   \n",
      "4     The verdict is not yet final; the court will h...   \n",
      "...                                                 ...   \n",
      "2998         A zero may be sufficient for the Bosnians.   \n",
      "2999  \"It is a good result, which nevertheless carri...   \n",
      "3000  \"We are going to play a team which has many te...   \n",
      "3001  As already in Zenica, the Portuguese would pla...   \n",
      "3002  A good idea, provided that it will, prove real...   \n",
      "\n",
      "                                                     es  \n",
      "0     El parlamento no apoyó una enmienda para liber...  \n",
      "1     El Parlamento de Ucrania ha rechazado hoy la p...  \n",
      "2     La modificación abriría las puertas a la excar...  \n",
      "3     En octubre, Tymoshenko fue sentenciada a siete...  \n",
      "4     La sentencia aún no es firme, el tribunal de a...  \n",
      "...                                                 ...  \n",
      "2998  A los bosnios les podría llegar un empate, aun...  \n",
      "2999  \"Es un buen resultado, pero a la vez conlleva ...  \n",
      "3000  \"Vamos a jugar contra un equipo que posee una ...  \n",
      "3001  Al igual que en Zenica, los portugueses irán c...  \n",
      "3002  Una buena idea, siempre que, esta vez, sea rea...  \n",
      "\n",
      "[3003 rows x 2 columns]\n",
      "Test:\n",
      "                                                     en  \\\n",
      "0     A Republican strategy to counter the re-electi...   \n",
      "1     Republican leaders justified their policy by t...   \n",
      "2     However, the Brennan Centre considers this a m...   \n",
      "3     Indeed, Republican lawyers identified only 300...   \n",
      "4     One thing is certain: these new provisions wil...   \n",
      "...                                                 ...   \n",
      "2995               We have an indulgence from the Pope.   \n",
      "2996  Restall noted that over the years there has be...   \n",
      "2997  Students and teachers are taking the date ligh...   \n",
      "2998  Some said they plan to go to \"end of the world...   \n",
      "2999  \"Maybe I'll call some friends so we can have a...   \n",
      "\n",
      "                                                     es  \n",
      "0     Una estrategia republicana para obstaculizar l...  \n",
      "1     Los dirigentes republicanos justificaron su po...  \n",
      "2     Ahora bien, el Centro Brennan considera esto ú...  \n",
      "3     De hecho, los abogados republicanos no han enc...  \n",
      "4     Una cosa es cierta: esas nuevas disposiciones ...  \n",
      "...                                                 ...  \n",
      "2995                       Tenemos un indulto del Papa.  \n",
      "2996  Restall hizo notar que a lo largo de los años ...  \n",
      "2997  Estudiantes y profesores se están tomando a la...  \n",
      "2998  Varios dijeron que piensan ir a fiestas \"del f...  \n",
      "2999  \"Tal vez llame a algunos amigos para que nos r...  \n",
      "\n",
      "[3000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "print(train_df)\n",
    "\n",
    "print(\"Dev:\")\n",
    "print(dev_df)\n",
    "\n",
    "print(\"Test:\")\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "train_df.to_csv(f\"{DATASET_PATH}/preprocessed/train.csv\", index=False)\n",
    "dev_df.to_csv(f\"{DATASET_PATH}/preprocessed/dev.csv\", index=False)\n",
    "test_df.to_csv(f\"{DATASET_PATH}/preprocessed/test.csv\", index=False)\n",
    "print(\"CSV files saved!\")"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files saved!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Save individual languages**\n",
    "\n",
    "Now we take a look at the Pandas object before saving it to CSV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual languages saved!\n"
     ]
    }
   ],
   "source": [
    "# For Training\n",
    "train_df_src = train_df[\"en\"]\n",
    "train_df_trg = train_df[\"es\"]\n",
    "train_df_src.to_csv(f\"{DATASET_PATH}/preprocessed/train_en.csv\", index=False)\n",
    "train_df_trg.to_csv(f\"{DATASET_PATH}/preprocessed/train_es.csv\", index=False)\n",
    "\n",
    "# For testing\n",
    "dev_df_src = dev_df[\"en\"]\n",
    "dev_df_trg = dev_df[\"es\"]\n",
    "dev_df_src.to_csv(f\"{DATASET_PATH}/preprocessed/dev_en.csv\", index=False)\n",
    "dev_df_trg.to_csv(f\"{DATASET_PATH}/preprocessed/dev_es.csv\", index=False)\n",
    "print(\"Individual languages saved!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}